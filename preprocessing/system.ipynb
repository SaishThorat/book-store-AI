{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"D:/Work/Hackathon/AI_ML/Dev/Dataset/D_new/\"\n",
    "model_route = r\"D:/Work/Hackathon/AI_ML/Dev/Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframe_pth= model_route + \"merged_dataframe_with_sentiment_labels.csv\"\n",
    "merged_df= pd.read_csv(merged_dataframe_pth)\n",
    "# merged_df=merged_df.fillna('')\n",
    "merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'User_id', 'review/helpfulness', 'review/score',\n",
       "       'review/time', 'review/summary', 'review/text', 'description',\n",
       "       'authors', 'image', 'publisher', 'publishedDate', 'categories',\n",
       "       'ratingsCount', 'sentiment_score', 'sentiment_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.shape --- 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df[['Title','review/helpfulness','publishedDate']][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in merged_df[\"review/helpfulness\"]:\n",
    "#   if \"/\" not in i:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df[['sentiment_score','review/text','sentiment_label']][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of user and item indices\n",
    "user_ids = merged_df['User_id'].unique()\n",
    "item_ids = merged_df['Title'].unique()\n",
    "user_to_index = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "item_to_index = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "index_to_title = {idx: title for title, idx in item_to_index.items()}\n",
    "\n",
    "# Convert user and item indices to tensors\n",
    "user_indices = torch.tensor([user_to_index[user_id] for user_id in merged_df['User_id']], dtype=torch.long)\n",
    "item_indices = torch.tensor([item_to_index[item_id] for item_id in merged_df['Title']], dtype=torch.long)\n",
    "ratings = torch.tensor(merged_df['review/score'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.hidden_layer = nn.Linear(embedding_dim * 2, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedded = self.user_embedding(user_indices)\n",
    "        item_embedded = self.item_embedding(item_indices)\n",
    "        concatenated = torch.cat([user_embedded, item_embedded], dim=1)\n",
    "        hidden_output = self.relu(self.hidden_layer(concatenated))\n",
    "        output = self.output_layer(hidden_output)\n",
    "        return output\n",
    "\n",
    "    def get_similar_titles(self, input_title_index, top_k=100):\n",
    "        device = self.item_embedding.weight.device  # Get the device of the embeddings\n",
    "\n",
    "        # Move the input title index to the same device as the model\n",
    "        input_title_index = torch.tensor([input_title_index], device=device)\n",
    "\n",
    "        # Get the embedding for the input title\n",
    "        input_title_embedding = self.item_embedding(input_title_index)\n",
    "\n",
    "        # Get embeddings for all titles\n",
    "        all_title_embeddings = self.item_embedding.weight\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarities = F.cosine_similarity(input_title_embedding, all_title_embeddings)\n",
    "\n",
    "        # Get indices of top-k similar titles\n",
    "        #argsort returns the indices that sort a tensor along a given dimension in ascending order(default) by value.\n",
    "        similar_title_indices = torch.argsort(similarities, descending=True)[:top_k]\n",
    "\n",
    "        # Convert indices to a list of titles\n",
    "        similar_titles = [index_to_title[idx.item()] for idx in similar_title_indices]\n",
    "        #we are using item() to get scalar value instead of tensor which can be used as an key index for dictionary\n",
    "        return similar_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollaborativeFilteringModel(\n",
       "  (user_embedding): Embedding(118335, 100)\n",
       "  (item_embedding): Embedding(36537, 100)\n",
       "  (hidden_layer): Linear(in_features=200, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = model_route + \"collaborative_filtering_model.pth\"\n",
    "# Load the entire model\n",
    "model_loaded = torch.load(model_path, map_location=device)\n",
    "model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of CollaborativeFilteringModel(\n",
       "  (user_embedding): Embedding(118335, 100)\n",
       "  (item_embedding): Embedding(36537, 100)\n",
       "  (hidden_layer): Linear(in_features=200, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 4.3365\n"
     ]
    }
   ],
   "source": [
    "user_index = torch.tensor([user_to_index['A30TK6U7DNS82R']], dtype=torch.long)\n",
    "item_index = torch.tensor([item_to_index['The Insiders (Insiders (Bloomsbury))']], dtype=torch.long)\n",
    "user_index , item_index= user_index.to(device), item_index.to(device)\n",
    "prediction = model_loaded(user_index, item_index).item()\n",
    "print(f'Predicted Rating: {prediction:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the content-based filtering model\n",
    "class ContentBasedFilteringModel(nn.Module):\n",
    "    def __init__(self, num_categories, num_authors, num_titles, embedding_dim):\n",
    "        super(ContentBasedFilteringModel, self).__init__()\n",
    "        self.category_embedding = nn.Embedding(num_categories, embedding_dim)\n",
    "        self.author_embedding = nn.Embedding(num_authors, embedding_dim)\n",
    "        self.title_embedding = nn.Embedding(num_titles, embedding_dim)\n",
    "        self.sentiment_linear = nn.Linear(4 * embedding_dim, 1)\n",
    "\n",
    "    def forward(self, category_indices, author_indices, title_indices, sentiment_scores):\n",
    "        category_embedded = self.category_embedding(category_indices)\n",
    "        author_embedded = self.author_embedding(author_indices)\n",
    "        title_embedded = self.title_embedding(title_indices)\n",
    "        sentiment_expanded = sentiment_scores.unsqueeze(1).expand_as(category_embedded)\n",
    "        # It serves as a constant tensor that gets expanded to match the size of category_embedded for concatenation, and its values remain fixed throughout training\n",
    "        #self.expand_as(other) is equivalent to self.expand(other.size()).\n",
    "\n",
    "        concatenated = torch.cat([category_embedded, author_embedded, title_embedded, sentiment_expanded], dim=1)\n",
    "        output = self.sentiment_linear(concatenated)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentBasedFilteringModel(\n",
       "  (category_embedding): Embedding(1168, 64)\n",
       "  (author_embedding): Embedding(28713, 64)\n",
       "  (title_embedding): Embedding(36537, 64)\n",
       "  (sentiment_linear): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = model_route + \"content_based_filtering_model.pth\"\n",
    "# Load the entire model\n",
    "cbf_model_loaded = torch.load(model_path, map_location=device)\n",
    "cbf_model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collaborative_recommendations(model, title, num_recommendations=100):\n",
    "\n",
    "\n",
    "    #item_to_index = {title: idx for idx, title in enumerate(item_ids)}\n",
    "    # Get index of the input title\n",
    "    input_title_index = item_to_index[title] # have already declared this before in above cells\n",
    "\n",
    "    # Get recommendations using the collaborative filtering model\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Call the custom method to get similar titles\n",
    "        similar_titles = model.get_similar_titles(input_title_index, top_k=num_recommendations)\n",
    "\n",
    "\n",
    "    # Return the recommended titles\n",
    "    return similar_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_title = \"From Potter's Field\"\n",
    "collab_recommendations = get_collaborative_recommendations(model_loaded, input_title,num_recommendations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From Potter's Field\",\n",
       " 'Railroad Ferries of the Hudson and Stories of a Deck Hand',\n",
       " 'Bad Dogs Need It: Good Dogs Deserve It: An Encyclopedia of Behavior Problems and Training Solutions',\n",
       " 'Yamaha Outboard Shop Manual: 2-90 Hp Two-Stroke, 1999-2002 (Includes Jet Drives (Clymer Marine Repair)',\n",
       " 'Hoax: The Inside Story of the Howard Hughes-Clifford Irving Affair',\n",
       " \"Enough About You, Let's Talk About Me: How to Recognize and Manage the Narcissists in Your Life\",\n",
       " 'Dave Barry Does Japan',\n",
       " 'A Search of African American Life, Achievement And Culture: First Search',\n",
       " 'Lyre of Orpheus (G K Hall Large Print Book Series)',\n",
       " 'The Line of Beauty: A Novel']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_recommendations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_sentiment_aggregated = merged_df.groupby(['Title','authors','categories'])['sentiment_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of unique categories, authors, and titles\n",
    "unique_categories = merged_df['categories'].unique()\n",
    "unique_authors = merged_df['authors'].unique()\n",
    "unique_titles = title_sentiment_aggregated['Title'].unique()\n",
    "\n",
    "category_to_index = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "author_to_index = {author: idx for idx, author in enumerate(unique_authors)}\n",
    "title_to_index = {title: idx for idx, title in enumerate(unique_titles)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categories, authors, titles to tensors\n",
    "category_indices = torch.tensor([category_to_index[category] for category in title_sentiment_aggregated['categories']], dtype=torch.long)\n",
    "author_indices = torch.tensor([author_to_index[author] for author in title_sentiment_aggregated['authors']], dtype=torch.long)\n",
    "title_indices = torch.tensor([title_to_index[title] for title in title_sentiment_aggregated['Title']], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(content_based_model, collaborative_recommendations):\n",
    "    # Assuming you have a mapping of titles to details (categories, authors, sentiment_scores)\n",
    "    #nested dictionary\n",
    "    title_details = title_sentiment_aggregated.set_index('Title')[['categories', 'authors', 'sentiment_score']].to_dict(orient='index')\n",
    "\n",
    "    # Extract details for collaborative recommendations\n",
    "    details = [title_details[title] for title in collaborative_recommendations]\n",
    "\n",
    "    # Convert details to tensors\n",
    "    category_indices = torch.tensor([category_to_index[detail['categories']] for detail in details], dtype=torch.long)\n",
    "    author_indices = torch.tensor([author_to_index[detail['authors']] for detail in details], dtype=torch.long)\n",
    "    title_indices = torch.tensor([title_to_index[title] for title in collaborative_recommendations], dtype=torch.long)\n",
    "    sentiment_scores = torch.tensor([detail['sentiment_score'] for detail in details], dtype=torch.float32)\n",
    "    category_indices, author_indices, title_indices, sentiment_scores= category_indices.to(device), author_indices.to(device), title_indices.to(device), sentiment_scores.to(device)\n",
    "    # Assuming you have a function to get predictions from the content-based model\n",
    "    content_based_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        predictions = content_based_model(category_indices, author_indices, title_indices, sentiment_scores)\n",
    "\n",
    "    # Sort titles based on the predictions\n",
    "    sorted_titles = [title for _, title in sorted(zip(predictions, collaborative_recommendations), reverse=True)]\n",
    "\n",
    "    # Return the sorted titles\n",
    "    return sorted_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_content_based_recommendations(cbf_model_loaded, collab_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Encyclopedia of 7700 Illustrations',\n",
       " 'North from Mexico: The Spanish-Speaking People of the United States',\n",
       " 'Spontaneous Remission: An Annotated Bibliography',\n",
       " 'Introduction to the Biology of Marine Life',\n",
       " 'Higher Ground - A Novel in Three Parts',\n",
       " 'Classic Wiley: A Lifetime of Punchers, Players, Punks and Prophets (Great American Sportswriters)',\n",
       " 'The battle of Dienbienphu',\n",
       " 'Morning, Noon and Night',\n",
       " 'Dr. Frankenstein and World Systems',\n",
       " 'Cathay: A Journey in Search of Old China (Destinations)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_name_matching(partial_name, all_books):\n",
    "    matching_titles = [title for title in all_books if partial_name.lower() in title.lower()]\n",
    "    unique_matching_titles = list(set(matching_titles))\n",
    "    if len(unique_matching_titles) == 0:\n",
    "        return \"404\", \"Invalid !! \"\n",
    "    print(\"You probably searched for :\", unique_matching_titles[0] )\n",
    "    return unique_matching_titles[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You probably searched for : An Unofficial Muggle's Guide to the Wizarding World: Exploring the Harry Potter Universe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"An Unofficial Muggle's Guide to the Wizarding World: Exploring the Harry Potter Universe\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = partial_name_matching('harry potter',merged_df['Title'])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You probably searched for : Superman: No Limits!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Actor's Book of Contemporary Stage Monologues (More Than 150 Monologues from Over 70 Playwrights)\",\n",
       " \"A Midsummer Night's Dream (Cliffs Complete)\",\n",
       " 'American Bee: The National Spelling Bee and the Culture of Word Nerds',\n",
       " 'Life. Be There at Ten Til.: A Collection of Homegrown Wisdom',\n",
       " 'Love Spell',\n",
       " 'Your Perfect Right: Assertiveness and Equality in Your Life and Relationships',\n",
       " 'Rangers and sovereignty,',\n",
       " 'Superman: No Limits!',\n",
       " 'Demon Box',\n",
       " \"Dark Canyon (THE COLLECTOR'S EDITION)\",\n",
       " 'Killing Orders',\n",
       " \"Caring for Your Child with Severe Food Allergies: Emotional Support and Practical Advice from a Parent Who's Been There\",\n",
       " 'The Franco-Prussian War 1870-1871 (Essential Histories)',\n",
       " 'Teach Yourself Turbo C++ 4.5 for Windows in 21 Days (Teach Yourself in 21 Days)',\n",
       " \"Queen's Gambit\",\n",
       " 'Kingdom Hearts Official Strategy Guide',\n",
       " 'The Essential Whitewater Kayaker: A Complete Course',\n",
       " 'Blame! Vol. 1',\n",
       " \"You Just Don't Understand\",\n",
       " 'The hockey sweater',\n",
       " \"Zane's Gettin' Buck Wild: Sex Chronicles II\",\n",
       " 'Death and the Invisible Powers: The World of Kongo Belief',\n",
       " 'CliffsStudySolver Chemistry',\n",
       " 'The Jewel Ornament Of Liberation: The Wish-Fulfilling Gem Of The Noble Teachings',\n",
       " 'An ABC of Music (Oxford Paperback Reference)',\n",
       " \"Heritage of Great Evangelical Teaching: The best of classic theological and devotional writings from some of history's greatest evangelical leaders\",\n",
       " 'Python Standard Library (Nutshell Handbooks) with',\n",
       " \"Expert Spring MVC and Web Flow (Expert's Voice in Java)\",\n",
       " 'Environmental Overkill: Whatever Happened to Common Sense?',\n",
       " \"Murach's CICS Desk Reference\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommendation_system(title, num_recommendations=30):\n",
    "    input_title = partial_name_matching(title, merged_df['Title'])\n",
    "    return get_content_based_recommendations(cbf_model_loaded, get_collaborative_recommendations( model_loaded, input_title,num_recommendations))\n",
    "\n",
    "recommendation_system(\"Superman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
